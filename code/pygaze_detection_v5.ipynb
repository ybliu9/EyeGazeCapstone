{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15659856"
   },
   "source": [
    "This code is meant to help you get started with your project and it adapted from examples contained here: https://github.com/esdalmaijer/PyGaze/tree/master/examples. Please note that this code requires the eye tracker, so do not try to run the code yet unless you want to comment out the tracker lines and play with the display. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip install keyboard\n",
    "#!pip install PyLink\n",
    "#!pip install pylink==0.3.2\n",
    "#!pip install -r requirements.txt\n",
    "#!pip install --index-url=https://pypi.sr-support.com sr-research-pylink"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#path = 'C:\\\\Users\\\\Chloe\\\\Documents'\n",
    "#os.chdir(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# import packages\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "from collections import defaultdict\n",
    "import keyboard\n",
    "import pylink\n",
    "\n",
    "from pygaze.libscreen import Display, Screen\n",
    "from pygaze.libinput import Keyboard\n",
    "from pygaze.eyetracker import EyeTracker\n",
    "from pygaze.liblog import Logfile\n",
    "import pygaze.libtime as timer\n",
    "from pygaze.mouse import Mouse\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Self-built package\n",
    "from pygazeplot.gazeplotter import *\n",
    "from pygazeplot.preprocess import *\n",
    "from pygazeplot.constants import *\n",
    "\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#i=18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Up Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['img22.png', 'img29.png', 'img37.png', 'img82.png']\n"
     ]
    }
   ],
   "source": [
    "# be used to determine where to store and retrieve data files\n",
    "DIR = os.path.dirname('C:\\\\Users\\\\Chloe\\\\Documents\\\\Capstone\\\\')\n",
    "# the TESTDIR is the path to the directory where test images and data would be stored\n",
    "TESTDIR = os.path.join(DIR, 'Table_extraction')\n",
    "# the IMGDIR is the path to the directory that contains the image files\n",
    "IMGDIR = os.path.join(TESTDIR, 'dataset\\\\test_img')\n",
    "# the IMGDIR is the path to the directory that contains the image files\n",
    "RESULTDIR = os.path.join(TESTDIR, 'runs\\\\detect')\n",
    "\n",
    "# read all image names\n",
    "images = [f for f in os.listdir(IMGDIR) if f.endswith('.png')]\n",
    "print(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "220417-145312_Chloe_lower_S60_D10_F5\n"
     ]
    }
   ],
   "source": [
    "# Name of participant\n",
    "USER_NAME = 'Chloe'\n",
    "\n",
    "# 1. Device positioning\n",
    "#    The angle between device and eyes (e.g. lower, upper, lowerleft)\n",
    "ANGLE = 'lower'                \n",
    "#    The distance between the participant and the display (cm)\n",
    "SCREENDIST = 60.0             \n",
    "\n",
    "\n",
    "# 2. Noise (distractions on page, quick blinks, eyes out of screen, etc.)\n",
    "#    The noisy situations in experiment (e.g. dstr, qb, eo)\n",
    "NOISE = ''                    \n",
    "\n",
    "\n",
    "# 3. Display time: time of image displayed on the screen\n",
    "#    Maximum length of time for each image to be displayed (ms)\n",
    "MAXTRIALTIME = 10000         \n",
    "\n",
    "\n",
    "# 4. Fixation time: time of eyes fixed on AOI\n",
    "#    Maximum length of time for fixation (s)\n",
    "MAXFIXTIME = 5      \n",
    "\n",
    "\n",
    "# 5. Number of images displayed at each experiment\n",
    "ntrials = len(images)\n",
    "\n",
    "# name used for log files, make this something unique (for example dependent on timestamp)\n",
    "l = [time.strftime(\"%y%m%d-%H%M%S\", time.localtime()), \n",
    "     USER_NAME, \n",
    "     ANGLE, \n",
    "     'S'+str(int(SCREENDIST)),\n",
    "     NOISE, \n",
    "     'D'+str(MAXTRIALTIME//1000), \n",
    "     'F'+str(MAXFIXTIME)]\n",
    "\n",
    "LOGFILENAME = '_'.join([s for s in l if s!='']) \n",
    "print(LOGFILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Detection with CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  2022-3-29 torch 1.11.0+cpu CPU\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp12/weights/best.pt'], source=dataset/test_img, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=cpu, view_img=False, save_txt=True, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "Model Summary: 476 layers, 87198694 parameters, 0 gradients, 217.1 GFLOPs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/4 C:\\Users\\Chloe\\Documents\\Capstone\\Table_extraction\\dataset\\test_img\\img22.png: 640x512 1 table, Done. (1.239s)\n",
      "image 2/4 C:\\Users\\Chloe\\Documents\\Capstone\\Table_extraction\\dataset\\test_img\\img29.png: 640x512 1 table, Done. (1.226s)\n",
      "image 3/4 C:\\Users\\Chloe\\Documents\\Capstone\\Table_extraction\\dataset\\test_img\\img37.png: 640x512 2 tables, Done. (1.685s)\n",
      "image 4/4 C:\\Users\\Chloe\\Documents\\Capstone\\Table_extraction\\dataset\\test_img\\img82.png: 640x512 2 tables, Done. (1.699s)\n",
      "Results saved to \u001b[1mruns\\detect\\exp20\u001b[0m\n",
      "4 labels saved to runs\\detect\\exp20\\labels\n",
      "Done. (6.023s)\n",
      "Wall time: 8.73 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "%run detect.py --weights runs/train/exp12/weights/best.pt --source dataset/test_img --device cpu --save-crop --save-txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  img_name                                              boxes  \\\n",
      "0    img22          [[0.50237, 0.178882, 0.796209, 0.149068]]   \n",
      "1    img29           [[0.49921, 0.428571, 0.78673, 0.131677]]   \n",
      "2    img37  [[0.5, 0.562733, 0.742543, 0.121739], [0.50235...   \n",
      "3    img82  [[0.481833, 0.79441, 0.748815, 0.180124], [0.4...   \n",
      "\n",
      "                                          box_pixels  \n",
      "0  [[65.58299950000001, 84.00014, 568.39846049999...  \n",
      "1  [[66.57650499999998, 291.9996625, 563.429675, ...  \n",
      "2  [[80.97022650000001, 404.0001175, 550.0297735,...  \n",
      "3  [[67.5706395, 567.00014, 540.5752745, 711.9999...  \n"
     ]
    }
   ],
   "source": [
    "# find the directory that contains prediction results\n",
    "exps = os.listdir(RESULTDIR)\n",
    "exps = sorted([e for e in exps if e != 'exp' and e.startswith('exp')], key = lambda x: int(x[3:]))\n",
    "PREDDIR = os.path.join(RESULTDIR, exps[-1])\n",
    "LB_PREDDIR = os.path.join(PREDDIR, 'labels')\n",
    "\n",
    "# make new directories for data and plots\n",
    "def new_dir(parent, new):\n",
    "    path = os.path.join(parent, new)\n",
    "    if not os.path.exists(path):\n",
    "        os.mkdir(path)\n",
    "    return path\n",
    "\n",
    "PLOTDIR = new_dir(PREDDIR, 'plots')\n",
    "DATADIR = new_dir(PREDDIR, 'gaze_data')\n",
    "\n",
    "# Obtain predicted table coordinates\n",
    "coords = pred_coords(LB_PREDDIR)\n",
    "print(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pygaze Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5e5ad1db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.1.2 (SDL 2.0.18, Python 3.8.3)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "Initiation time spent: 70.321 s\n",
      "True\n",
      "Calibration time spent: 26.657 s\n",
      "function not supported yet\n",
      "function not supported yet\n",
      "function not supported yet\n",
      "function not supported yet\n",
      "Experiment time spent: 88.189 s\n",
      "Disconnection time spent: 0.491 s\n",
      "Preprocessing time spent: 0.056 s\n",
      "Prediction time spent: 0.007 s\n",
      "12.8176 \tWARNING \tMonitor specification not found. Creating a temporary one...\n",
      "12.8219 \tWARNING \tUser requested fullscreen with size [1024 1024], but screen is actually [1536, 864]. Using actual size\n",
      "14.1765 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "84.4367 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "88.8592 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "89.0681 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7100 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7156 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7225 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7268 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7324 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7374 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7429 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7473 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7528 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7574 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7634 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7676 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7738 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7779 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7832 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7878 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7939 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.7984 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "112.8007 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "115.5751 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "205.2114 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "205.7150 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "206.9787 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "208.9761 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "208.9912 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "211.4889 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "211.4952 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "213.6565 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "213.6664 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "215.4710 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "215.4807 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "219.1422 \tWARNING \tTextStim.alignHoriz is deprecated. Use alignText and anchorHoriz attributes instead\n",
      "Wall time: 3min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# path to logfile establishes where the gaze data will be written\n",
    "LOGFILE = os.path.join(DATADIR, LOGFILENAME)\n",
    "\n",
    "# initialize objects\n",
    "disp = Display()\n",
    "#ip=\"127.0.0.1\"\n",
    "ip = \"172.20.10.3\"\n",
    "scr = Screen()\n",
    "\n",
    "mouse = Mouse(mousebuttonlist=None, timeout=10000)\n",
    "mouse.set_visible(visible=True)\n",
    "\n",
    "# create keyboard object\n",
    "kb = Keyboard(keylist=['space'], timeout=10000)\n",
    "init_t0 = time.time()\n",
    "tracker = EyeTracker(disp, debug=True, logfile=LOGFILE)\n",
    "\n",
    "# establish data connection to tracker\n",
    "state=True\n",
    "acknowledged, timeout = tracker.opengaze._send_message('SET', \\\n",
    "    'ENABLE_SEND_DATA', \\\n",
    "    values=[('STATE', int(state))], \\\n",
    "    wait_for_acknowledgement=True)\n",
    "init_t1 = time.time()\n",
    "init_t = round(init_t1-init_t0,3)\n",
    "print('Initiation time spent: ' + str(init_t) + ' s')\n",
    "print(acknowledged)\n",
    "\n",
    "# if you want to log any additional information, you will do it this way (saved to different file than gaze data)\n",
    "log = Logfile()\n",
    "#log.write([\"trialnr\",\"image\",\"imgtime\"])\n",
    "\n",
    "# set up experiment and perform calibration\n",
    "\n",
    "# display instructions\n",
    "scr.draw_text(text=\"Please keep still during the experiment. Click the mouse to start the calibration.\", fontsize=20)\n",
    "disp.fill(scr)\n",
    "disp.show()\n",
    "\n",
    "# wait for a keypress\n",
    "#kb.get_key(keylist=None, timeout=None, flush=True)\n",
    "mouse.get_clicked()\n",
    "\n",
    "# calibrate the eye tracker\n",
    "cal_t0 = time.time()\n",
    "tracker.calibrate()\n",
    "cal_t1 = time.time()\n",
    "cal_t = round(cal_t1-cal_t0,3)\n",
    "print('Calibration time spent: ' + str(cal_t) + ' s')\n",
    "\n",
    "screenshot_name = time.strftime(\"%y%m%d-%H%M%S\", time.localtime())+\"_calibration.png\"\n",
    "disp.make_screenshot(filename=os.path.join(PREDDIR, screenshot_name))\n",
    "# perform experiment\n",
    "\n",
    "scr.clear()\n",
    "txt = f'You will see {ntrials} images in sequence, each containing one or more tables. '\n",
    "txt = txt + f'Please gaze at a table of interest in each image for {MAXTRIALTIME//1000} seconds.'\n",
    "txt = txt + '\\n\\n' + f'Click the mouse to start.'\n",
    "scr.draw_text(text= txt, fontsize=20)\n",
    "disp.fill(scr)\n",
    "disp.show()\n",
    "\n",
    "# wait for a keypress\n",
    "#kb.get_key(keylist=None, timeout=None, flush=True)\n",
    "mouse.get_clicked()\n",
    "\n",
    "#Generate random numbers between 10 and 30\n",
    "#andomlist = random.sample(range(0, len(images)), ntrials)\n",
    "\n",
    "exp_t0 = time.time()\n",
    "# loop through all trials\n",
    "for trialnr in range(ntrials):\n",
    "    \n",
    "    # gerate random index\n",
    "    #i = random.randrange(len(images))\n",
    "    \n",
    "    # PREPARE TRIAL\n",
    "    # draw the image\n",
    "    scr.clear()\n",
    "    scr.draw_image(os.path.join(IMGDIR,images[trialnr]),scale=RESCALE)\n",
    "    \n",
    "    # RUN TRIAL\n",
    "    # start tracking\n",
    "    tracker.start_recording()\n",
    "    tracker.log(\"TRIALSTART %d\" % trialnr)\n",
    "    tracker.log(\"IMAGENAME %s\" % images[trialnr])\n",
    "    tracker.status_msg(\"trial %d/%d\" % (trialnr+1, ntrials))\n",
    "    \n",
    "    # present image\n",
    "    disp.fill(scr)\n",
    "    t0 = disp.show()\n",
    "    tracker.log(\"image online at %d\" % t0)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    while True:  \n",
    "        # key is pressed or time exceeds limit\n",
    "        if keyboard.is_pressed('space'):\n",
    "            break\n",
    "        elif (time.time() - start_time) > (MAXTRIALTIME / 1000):  \n",
    "            break \n",
    "    \n",
    "    timer.pause(FIXATIONTIME)\n",
    "    \n",
    "    # reset screen\n",
    "    disp.fill()\n",
    "    t1 = disp.show()\n",
    "    tracker.log(\"image offline at %d\" % t1)\n",
    "\n",
    "    \n",
    "    # stop recording\n",
    "    tracker.log(\"TRIALEND %d\" % trialnr)\n",
    "    tracker.stop_recording()\n",
    "    \n",
    "    # TRIAL AFTERMATH\n",
    "    # bookkeeping\n",
    "    log.write([trialnr, images[trialnr], t1-t0])\n",
    "    \n",
    "    # inter trial interval\n",
    "    timer.pause(500)\n",
    "    \n",
    "# close experiment\n",
    "# loading message\n",
    "scr.clear()\n",
    "exp_t1 = time.time()\n",
    "exp_t = round(exp_t1-exp_t0,3)\n",
    "print('Experiment time spent: ' + str(exp_t) + ' s')\n",
    "\n",
    "scr.draw_text(text=\"Transferring the data file, please wait...\", fontsize=20)\n",
    "disp.fill(scr)\n",
    "disp.show()\n",
    "\n",
    "close_t0 = time.time()\n",
    "# neatly close connection to the tracker\n",
    "# (this will close the data file, and copy it to the stimulus PC)\n",
    "tracker.close()\n",
    "\n",
    "# close the logfile\n",
    "log.close()\n",
    "\n",
    "close_t1 = time.time()\n",
    "close_t = round(close_t1-close_t0,3)\n",
    "print('Disconnection time spent: ' + str(close_t) + ' s')\n",
    "\n",
    "############################## preprocess ##################################\n",
    "\n",
    "scr.clear()\n",
    "scr.draw_text(text=\"Processing data...\", fontsize=20)\n",
    "disp.fill(scr)\n",
    "disp.show()\n",
    "\n",
    "prep_t0 = time.time()\n",
    "for file in os.listdir(DATADIR):\n",
    "    if not file.startswith(LOGFILENAME):\n",
    "        continue\n",
    "    elif file.endswith(\".tsv\"):\n",
    "        d = file \n",
    "    elif file.endswith(\".txt\"):\n",
    "        l = file\n",
    "#print('d:',d, '\\nl:',l)\n",
    "data = process_data(DATADIR, d, l, ntrials)\n",
    "\n",
    "data = data[data.IMGID != -1]\n",
    "filename = os.path.join(DATADIR,'trim_edge_'+time.strftime(\"%y%m%d-%H%M%S\", time.localtime())+'.csv')\n",
    "trimmed = trim_edge(data=data, filename = filename)\n",
    "\n",
    "prep_t1 = time.time()\n",
    "prep_t = round(prep_t1-prep_t0,3)\n",
    "print('Preprocessing time spent: ' + str(prep_t) + ' s')\n",
    "\n",
    "#plot heapmap and scanpath\n",
    "for img in range(len(images)):\n",
    "    imgname = images[img]\n",
    "    d = trimmed[trimmed.IMGID == imgname.upper()]\n",
    "\n",
    "    HPATH = os.path.join(PLOTDIR, imgname.rstrip('.png')+'_heatmap.png')\n",
    "    SPATH = os.path.join(PLOTDIR, imgname.rstrip('.png')+'_scanpath.png')\n",
    "    imagefile = os.path.join(PREDDIR,imgname.lower())\n",
    "    draw_heatmap(d, imagefile=imagefile, durationweight=True, alpha=0.3, savefilename=HPATH)\n",
    "    #draw_scanpath(d, imagefile=imagefile, alpha=0.3, savefilename=SPATH)\n",
    "\n",
    "pred_t0 = time.time()    \n",
    "m = count_density(data=trimmed, boxes=coords, imglist = images)\n",
    "pred_t1 = time.time()\n",
    "pred_t = round(pred_t1-pred_t0,3)\n",
    "print('Prediction time spent: ' + str(pred_t) + ' s')\n",
    "\n",
    "t = open(os.path.join(PREDDIR, 'density.txt'),\"w\")\n",
    "t.write(str(list(m.items())))\n",
    "t.close()\n",
    "############################### display results #############################\n",
    "\n",
    "scr.clear()\n",
    "txt = f'The tables have been saved to the local drive. '+'\\n'\n",
    "txt = txt + f'Click the mouse to see the potential Area of Interest (AOI).'\n",
    "scr.draw_text(text= txt, fontsize=20)\n",
    "disp.fill(scr)\n",
    "disp.show()\n",
    "\n",
    "# wait for a keypress or a mouseclick\n",
    "#kb.get_key(keylist=None, timeout=None, flush=True)\n",
    "mouse.get_clicked()\n",
    "\n",
    "for trialnr in range(ntrials):\n",
    "    \n",
    "    # PREPARE TRIAL\n",
    "    # draw the image\n",
    "    scr.clear()\n",
    "    scr.draw_image(os.path.join(PREDDIR,images[trialnr]),scale=1.0)\n",
    "    disp.fill(scr)\n",
    "    \n",
    "    \n",
    "    img_name = images[trialnr]\n",
    "    # predicted density\n",
    "    v = m[img_name]\n",
    "    i = v.index(max(v))\n",
    "    _x,_y,_w,_h = coords[coords.img_name == img_name.split('.')[0]].boxes.values[0][i]\n",
    "    #in pixels\n",
    "    edge_x = (DISPSIZE[0] - IMGSIZE[0])//2\n",
    "    edge_y = (DISPSIZE[1] - IMGSIZE[1])//2\n",
    "    x,y,w,h = (_x-_w/2)*IMGSIZE[0]+edge_x, (_y-_h/2)*IMGSIZE[1]+edge_y, _w*IMGSIZE[0], _h*IMGSIZE[1]\n",
    "    scr.draw_rect(colour='blue', x=x, y=y, w=w, h=h, pw=5)\n",
    "    disp.fill(scr)\n",
    "    \n",
    "    display_str = \"{}: {}%\".format('Density of fixations', v[i])\n",
    "    scr.draw_text(text=display_str, colour='blue', pos=(int(x+w), int(y+h+10)),centre = False, fontsize=20)\n",
    "    disp.fill(scr)\n",
    "    \n",
    "    txt = f'Click the mouse'+'\\n'\n",
    "    txt = txt + f'to show the' + '\\n'+ 'next image'\n",
    "    scr.draw_text(text=txt, pos=(DISPSIZE[0]-5, DISPSIZE[1]//2), centre = False, fontsize=20)\n",
    "    disp.fill(scr)\n",
    "    # present image\n",
    "    disp.fill(scr)\n",
    "    disp.show()\n",
    "    SCRSHOT = 'AOI_prediction_'+img_name\n",
    "    disp.make_screenshot(filename=os.path.join(PLOTDIR, SCRSHOT))\n",
    "    \n",
    "    mouse.get_clicked()\n",
    "    \n",
    "    # reset screen\n",
    "    disp.fill()\n",
    "    disp.show()\n",
    "\n",
    "\n",
    "\n",
    "# exit message\n",
    "scr.clear()\n",
    "scr.draw_text(text=\"This is the end of this experiment. Thank you for participating!\\n\\n(click the mouse to exit)\", fontsize=20)\n",
    "disp.fill(scr)\n",
    "disp.show()\n",
    "\n",
    "t_list = [init_t, cal_t, exp_t, close_t, prep_t, pred_t]\n",
    "#print(t_list)\n",
    "\n",
    "# wait for a keypress\n",
    "#kb.get_key(keylist=None, timeout=None, flush=True)\n",
    "mouse.get_clicked()\n",
    "\n",
    "# close the Display\n",
    "disp.close()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    ".../Table_extraction/runs/detect\n",
    "﹂/exp\n",
    "    ﹂/crops                     #cropped tables from each test image\n",
    "        ﹂/table\n",
    "    ﹂/labels                    #coordinates of tables within each test image\n",
    "        ﹂imgxx.json\n",
    "        ﹂imgxx.txt\n",
    "    ﹂/gaze_data\n",
    "        ﹂xxx.tsv                #fixation points\n",
    "        ﹂xxx_log.txt            #experiment log\n",
    "        ﹂trimmed.csv            #cleaned data\n",
    "    ﹂/plots\n",
    "        ﹂imgxx_AOI.png          #AOI bounding box based on eye fixations\n",
    "        ﹂imgxx_heatmap.png      #fixation heatmap\n",
    "        ﹂imgxx_scanpath.png     #fixation scanpath     (optional)\n",
    "    ﹂calibration.png            #screenshot of calibration result\n",
    "    ﹂density.txt                #fixation distribution for each test image\n",
    "    ﹂imgxx.png                    #test image with tables detected"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "capstone_setup.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
